{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T05:23:48.153499Z",
     "start_time": "2020-11-29T05:23:45.341648Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQZOUYJWONJH",
    "outputId": "da5282c8-f9cb-48ad-a22a-3ce3dff808e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cowsay is already the newest version (3.03+dfsg2-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      " __________________________________\n",
      "/ Currently on Ubuntu 18.04.5 LTS  \\\n",
      "|                                  |\n",
      "\\ \\l                               /\n",
      " ----------------------------------\n",
      "        \\   ^__^\n",
      "         \\  (oo)\\_______\n",
      "            (__)\\       )\\/\\\n",
      "                ||----w |\n",
      "                ||     ||\n",
      "Sun Nov 29 13:23:46 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 2060    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P3    21W /  N/A |    422MiB /  5934MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1082      G   /usr/lib/xorg/Xorg                185MiB |\n",
      "|    0   N/A  N/A      1335      G   /usr/bin/gnome-shell               94MiB |\n",
      "|    0   N/A  N/A      2603      G   seadrive-gui                        3MiB |\n",
      "|    0   N/A  N/A      3904      G   ...AAAAAAAAA= --shared-files       48MiB |\n",
      "|    0   N/A  N/A      4141      G   ...AAAAAAAA== --shared-files       85MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      " ________________________________\n",
      "< All python packages installed! >\n",
      " --------------------------------\n",
      "        \\    ,-^-.\n",
      "         \\   !oYo!\n",
      "          \\ /./=\\.\\______\n",
      "               ##        )\\/\\\n",
      "                ||-----w||\n",
      "                ||      ||\n",
      "\n",
      "               Cowth Vader\n"
     ]
    }
   ],
   "source": [
    "# 输出hello message\n",
    "!sudo apt install cowsay -y\n",
    "!echo \"Currently on $(cat /etc/issue)\" | /usr/games/cowsay\n",
    "!nvidia-smi\n",
    "\n",
    "# 在Google-Colab运行时，切换到Googoe-Drive工作目录\n",
    "import os,sys,logging\n",
    "if not os.path.exists(\"datasets\"):\n",
    "  os.chdir(\"./drive/MyDrive/ABSA\")\n",
    "\n",
    "# 建立全局logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# 安装依赖项\n",
    "!pip install -r requirements.txt | grep ^\"already satisfied\"\n",
    "!/usr/games/cowsay -f vader  All python packages installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T05:23:50.092511Z",
     "start_time": "2020-11-29T05:23:48.157881Z"
    },
    "code_folding": [
     11,
     20,
     28,
     43,
     54,
     93
    ],
    "id": "CHAtVYUsSFRx"
   },
   "outputs": [],
   "source": [
    "# 定义工具函数，类\n",
    "import numpy as np\n",
    "import argparse\n",
    "from transformers import BertModel,BertTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# 设置全局随机种子\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(opt.seed)\n",
    "    torch.manual_seed(opt.seed)\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(opt.seed)\n",
    "# 将序列标准化到同样长度\n",
    "def normal_sequence(sequence, maxlen, dtype='int64', value=0):\n",
    "    x = (np.ones(maxlen) * value).astype(dtype)\n",
    "    trunc = sequence[:maxlen]\n",
    "    trunc = np.asarray(trunc, dtype=dtype)\n",
    "    x[:len(trunc)] = trunc\n",
    "    return x\n",
    "# 在Bert本身tokenizer功能之上，增加了标准化到指定长度功能\n",
    "class MyTokenizer:\n",
    "    def __init__(self, max_seq_len, pretrained_bert_name):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    # 使用BertTokenizer将文本转化为id向量，并按照指定的最大长度进行补完\n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(text))\n",
    "        sequence = sequence if len(sequence)>0 else [0]\n",
    "        return normal_sequence(sequence, self.max_seq_len)\n",
    "# 用于对原始数据进行加工，产生bert可用的数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, fname, tokenizer):\n",
    "        fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "        lines = fin.readlines()\n",
    "\n",
    "        all_data = []\n",
    "        for i in range(0, len(lines), 3):\n",
    "            text_left, _, text_right = [s.lower().strip() for s in lines[i].partition(\"$T$\")]\n",
    "            aspect = lines[i + 1].lower().strip()\n",
    "            polarity = lines[i + 2].strip()\n",
    "\n",
    "            text_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
    "            aspect_indices = tokenizer.text_to_sequence(aspect)\n",
    "            aspect_len = np.sum(aspect_indices != 0)\n",
    "            polarity = int(polarity) + 1 # 规范化到正整数\n",
    "\n",
    "            text_len = np.sum(text_indices != 0)\n",
    "            concat_bert_indices = tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
    "            concat_segments_indices = [0] * (text_len + 2) + [1] * (aspect_len + 1)\n",
    "            concat_segments_indices = normal_sequence(concat_segments_indices, tokenizer.max_seq_len)\n",
    "\n",
    "            data = {\n",
    "                'concat_bert_indices': concat_bert_indices,\n",
    "                'concat_segments_indices': concat_segments_indices,\n",
    "                'polarity': polarity,\n",
    "            }\n",
    "\n",
    "            all_data.append(data)\n",
    "        \n",
    "        fin.close()\n",
    "        \n",
    "        self.data = all_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "# 基于Bert的神经网络类，由 bert + dropout + fully-connected 三层构成\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, bert, opt):\n",
    "        super(Network, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.dense = nn.Linear(opt.bert_dim, opt.polarities_dim)\n",
    "\n",
    "    # 前向传播过程\n",
    "    def forward(self, inputs):\n",
    "        text_bert_indices, bert_segments_ids = inputs[0], inputs[1]\n",
    "        _, pooled_output = self.bert(text_bert_indices, token_type_ids=bert_segments_ids)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.dense(pooled_output)\n",
    "        return logits\n",
    "# 主类，\n",
    "class Instructor:\n",
    "    def __init__(self, opt):\n",
    "        # 创建bert-based model\n",
    "        self.opt = opt\n",
    "        self.tokenizer = MyTokenizer(opt.max_seq_len, opt.pretrained_bert_name)\n",
    "        bert = BertModel.from_pretrained(opt.pretrained_bert_name)\n",
    "        self.model = opt.model_class(bert, opt).to(opt.device)\n",
    "        \n",
    "        # 加载训练集\n",
    "        self.trainset = MyDataset(opt.dataset_file['train'], self.tokenizer)\n",
    "        assert 0 < opt.valset_ratio < 1\n",
    "        valset_len = int(len(self.trainset) * opt.valset_ratio)\n",
    "        self.trainset, self.valset = random_split(self.trainset, (len(self.trainset)-valset_len, valset_len)) # 分割一部分训练集为测试集\n",
    "        self.trainset = MyDataset(opt.dataset_file['train'], self.tokenizer) # 为了性能，将使用全量训练集\n",
    "\n",
    "        # 检查是否有显卡\n",
    "        if opt.device.type == 'cuda':\n",
    "            logger.info('cuda memory allocated: {}'.format(torch.cuda.memory_allocated(device=opt.device.index)))\n",
    "        \n",
    "        self._print_args()\n",
    "\n",
    "    def _print_args(self):\n",
    "        n_trainable_params, n_nontrainable_params = 0, 0\n",
    "        for p in self.model.parameters():\n",
    "            n_params = torch.prod(torch.tensor(p.shape))\n",
    "            if p.requires_grad:\n",
    "                n_trainable_params += n_params\n",
    "            else:\n",
    "                n_nontrainable_params += n_params\n",
    "        logger.info('> n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))\n",
    "        logger.info('> training arguments:')\n",
    "        for arg in vars(self.opt):\n",
    "            logger.info('>>> {0}: {1}'.format(arg, getattr(self.opt, arg)))\n",
    "\n",
    "    def _reset_params(self):\n",
    "        for child in self.model.children():\n",
    "            if type(child) != BertModel:  # skip bert params\n",
    "                for p in child.parameters():\n",
    "                    if p.requires_grad:\n",
    "                        if len(p.shape) > 1:\n",
    "                            self.opt.initializer(p)\n",
    "                        else:\n",
    "                            stdv = 1. / np.sqrt(p.shape[0])\n",
    "                            torch.nn.init.uniform_(p, a=-stdv, b=stdv)\n",
    "\n",
    "    def _train(self, criterion, optimizer, train_data_loader, val_data_loader):\n",
    "        max_val_acc = 0\n",
    "        max_val_f1 = 0\n",
    "        max_val_epoch = 0\n",
    "        global_step = 0\n",
    "        path = None\n",
    "        for i_epoch in range(self.opt.num_epoch):\n",
    "            logger.info('>' * 100)\n",
    "            logger.info('epoch: {}'.format(i_epoch))\n",
    "            n_correct, n_total, loss_total = 0, 0, 0\n",
    "            # switch model to training mode\n",
    "            self.model.train()\n",
    "            for i_batch, batch in enumerate(train_data_loader):\n",
    "                global_step += 1\n",
    "                # clear gradient accumulators\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                inputs = [batch[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
    "                outputs = self.model(inputs)\n",
    "                targets = batch['polarity'].to(self.opt.device)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
    "                n_total += len(outputs)\n",
    "                loss_total += loss.item() * len(outputs)\n",
    "                if global_step % self.opt.log_step == 0:\n",
    "                    train_acc = n_correct / n_total\n",
    "                    train_loss = loss_total / n_total\n",
    "                    logger.info('loss: {:.4f}, acc: {:.4f}'.format(train_loss, train_acc))\n",
    "\n",
    "            val_acc, val_f1 = self._evaluate_acc_f1(val_data_loader)\n",
    "            logger.info('> val_acc: {:.4f}, val_f1: {:.4f}'.format(val_acc, val_f1))\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                max_val_epoch = i_epoch\n",
    "                if not os.path.exists('state_dict'):\n",
    "                    os.mkdir('state_dict')\n",
    "                path = 'state_dict/val_acc_{}'.format(round(val_acc, 4))\n",
    "                torch.save(self.model.state_dict(), path)\n",
    "                logger.info('>> saved: {}'.format(path))\n",
    "            if val_f1 > max_val_f1:\n",
    "                max_val_f1 = val_f1\n",
    "            if i_epoch - max_val_epoch >= self.opt.patience:\n",
    "                print('>> early stop.')\n",
    "                break\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _evaluate_acc_f1(self, data_loader):\n",
    "        n_correct, n_total = 0, 0\n",
    "        t_targets_all, t_outputs_all = None, None\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i_batch, t_batch in enumerate(data_loader):\n",
    "                t_inputs = [t_batch[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
    "                t_targets = t_batch['polarity'].to(self.opt.device)\n",
    "                t_outputs = self.model(t_inputs)\n",
    "\n",
    "                n_correct += (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "                n_total += len(t_outputs)\n",
    "\n",
    "                if t_targets_all is None:\n",
    "                    t_targets_all = t_targets\n",
    "                    t_outputs_all = t_outputs\n",
    "                else:\n",
    "                    t_targets_all = torch.cat((t_targets_all, t_targets), dim=0)\n",
    "                    t_outputs_all = torch.cat((t_outputs_all, t_outputs), dim=0)\n",
    "\n",
    "        acc = n_correct / n_total\n",
    "        f1 = f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
    "        return acc, f1\n",
    "\n",
    "    \n",
    "    def evaluate(self, text, aspect):\n",
    "        aspect = aspect.lower().strip()\n",
    "        text_left, _, text_right = [s.strip() for s in text.lower().partition(aspect)]\n",
    "        text_indices = self.tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
    "        aspect_indices = self.tokenizer.text_to_sequence(aspect)\n",
    "        aspect_len = np.sum(aspect_indices != 0)\n",
    "        text_len = np.sum(text_indices != 0)\n",
    "        concat_bert_indices = self.tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
    "        concat_segments_indices = [0] * (text_len + 2) + [1] * (aspect_len + 1)\n",
    "        concat_segments_indices = normal_sequence(concat_segments_indices, self.tokenizer.max_seq_len)\n",
    "\n",
    "        data = {\n",
    "            'concat_bert_indices': concat_bert_indices,\n",
    "            'concat_segments_indices': concat_segments_indices,\n",
    "        }\n",
    "\n",
    "        t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
    "        t_outputs = self.model(t_inputs)\n",
    "        t_probs = F.softmax(t_outputs, dim=-1).cpu().numpy()\n",
    "\n",
    "        return t_probs\n",
    "\n",
    "    def run(self):\n",
    "        # Loss and Optimizer\n",
    "        _params = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        optimizer = self.opt.optimizer(_params, lr=self.opt.lr, weight_decay=self.opt.l2reg)\n",
    "        train_data_loader = DataLoader(dataset=self.trainset, batch_size=self.opt.batch_size, shuffle=True)\n",
    "        val_data_loader = DataLoader(dataset=self.valset, batch_size=self.opt.batch_size, shuffle=False)\n",
    "        self._reset_params()\n",
    "        \n",
    "        # 训练过程，并记录最优模型\n",
    "        best_model_path = self._train(nn.CrossEntropyLoss(), optimizer, train_data_loader, val_data_loader)\n",
    "        \n",
    "        # 将自身重载为最优模型\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "        print(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T05:25:14.689435Z",
     "start_time": "2020-11-29T05:23:50.093922Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLSkWZ2jV8Or",
    "outputId": "46c55d98-c650-4398-e3d1-263dd5ae5bc5",
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'bert-ada' at 'bert-ada/pytorch_model.bin'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: read(): fd 67 failed with Input/output error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-63a3c5bf17e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/games/cowsay \"Model Set Up~ Start Training!\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1f6c90d0ee8b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_bert_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_bert_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 raise OSError(\n\u001b[0;32m--> 954\u001b[0;31m                     \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m                     \u001b[0;34mf\"at '{resolved_archive_file}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'bert-ada' at 'bert-ada/pytorch_model.bin'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "
     ]
    }
   ],
   "source": [
    "# 参数指定，调参在此进行\n",
    "my_args = \"--seed 2020 --lr 1e-5 --pretrained_bert_name bert-ada\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', default=2e-5, type=float)\n",
    "parser.add_argument('--dropout', default=0.1, type=float)\n",
    "parser.add_argument('--l2reg', default=0.01, type=float)\n",
    "parser.add_argument('--num_epoch', default=20, type=int)\n",
    "parser.add_argument('--batch_size', default=16, type=int)\n",
    "parser.add_argument('--log_step', default=10, type=int)\n",
    "parser.add_argument('--bert_dim', default=768, type=int)\n",
    "parser.add_argument('--pretrained_bert_name', default='bert_base_uncased', type=str)\n",
    "parser.add_argument('--max_seq_len', default=85, type=int)\n",
    "parser.add_argument('--polarities_dim', default=3, type=int)\n",
    "parser.add_argument('--patience', default=5, type=int)\n",
    "parser.add_argument('--seed', default=1234, type=int, help='set seed for reproducibility')\n",
    "parser.add_argument('--valset_ratio', default=0.1, type=float, help='set ratio between 0 and 1 for validation support')\n",
    "\n",
    "opt = parser.parse_args(args=my_args.split())\n",
    "# 设置随机种子，保证多次训练结果都一样\n",
    "set_random_seed(opt.seed)\n",
    "opt.model_class = Network\n",
    "opt.dataset_file = {'train': './datasets/train.txt'}\n",
    "opt.inputs_cols = ['concat_bert_indices', 'concat_segments_indices']\n",
    "opt.initializer = torch.nn.init.xavier_uniform_\n",
    "opt.optimizer = torch.optim.Adam\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ins = Instructor(opt)\n",
    "!/usr/games/cowsay \"Model Set Up~ Start Training!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T05:25:14.692384Z",
     "start_time": "2020-11-29T05:23:45.345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练过程，如果仅进行读取模型和评估，则这一段代码不用运行\n",
    "from time import strftime, localtime\n",
    "if not os.path.exists('logs'):\n",
    "    os.mkdir('logs')\n",
    "log_file = './logs/{}{}.log'.format(strftime(\"%y%m%d-%H%M\", localtime()),my_args)\n",
    "logger.addHandler(logging.FileHandler(log_file))\n",
    "\n",
    "ins.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T05:25:14.693199Z",
     "start_time": "2020-11-29T05:23:45.346Z"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# 重新设置随机种子，保证无论训练完后还是直接载入模型，结果都不会变\n",
    "set_random_seed(opt.seed)\n",
    "\n",
    "# 加载当前最好的模型，因为未必每次都会训练，直接人为指定\n",
    "ins.model.load_state_dict(torch.load('state_dict/leader-0.9092'))\n",
    "ins.model = ins.model.to(opt.device)\n",
    "ins.model.eval()\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "# 声称预测结果\n",
    "rfile = open('./datasets/test.txt','r')\n",
    "wfile = open('./datasets/181220010.txt','w')\n",
    "\n",
    "for line in rfile.readlines():\n",
    "    line = line.strip(' \\n')\n",
    "    if \"$\" in line:\n",
    "        last_line = line\n",
    "    else:\n",
    "        last_line = last_line.split('$')\n",
    "        new_line = last_line[0] + line + last_line[2]\n",
    "        print(new_line)\n",
    "        segmentation = ins.evaluate(new_line, line).argmax(axis=-1) - 1\n",
    "        wfile.write(\"{}\\n\".format(segmentation[0]))\n",
    "\n",
    "rfile.close()\n",
    "wfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ABSA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1549px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}