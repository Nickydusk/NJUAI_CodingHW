{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "if not os.path.exists(\"data\"):\n",
    "    if not os.path.exists('baseline'):\n",
    "        os.chdir('Q:/Course/Sophomore_2/Introduce to Machine Learning/ML_HW7')\n",
    "    else:\n",
    "        os.chdir('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline只用到gps定位数据，即train_gps_path\n",
    "train_gps_path = 'data/train0523.csv'\n",
    "# train_gps_path = 'data/wash1_train.csv'\n",
    "test_data_path = 'data/A_testData0531.csv'\n",
    "# test_data_path = 'data/wash1_test.csv'\n",
    "order_data_path = 'data/loadingOrderEvent.csv'\n",
    "port_data_path = 'data/port.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取前1000000行\n",
    "debug = True\n",
    "NDATA = 1000000\n",
    "\n",
    "if debug:\n",
    "    train_data = pd.read_csv(train_gps_path,nrows=NDATA,header=None)\n",
    "else:\n",
    "    train_data = pd.read_csv(train_gps_path,header=None)\n",
    "\n",
    "train_data.columns = ['loadingOrder','carrierName','timestamp','longitude',\n",
    "                  'latitude','vesselMMSI','speed','direction','vesselNextport',\n",
    "                  'vesselNextportETA','vesselStatus','vesselDatasource','TRANSPORT_TRACE']\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, mode='train'):\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    if mode=='train':\n",
    "        data['vesselNextportETA'] = pd.to_datetime(data['vesselNextportETA'], infer_datetime_format=True)\n",
    "    elif mode=='test':\n",
    "        data['temp_timestamp'] = data['timestamp']\n",
    "        data['onboardDate'] = pd.to_datetime(data['onboardDate'], infer_datetime_format=True)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], infer_datetime_format=True)\n",
    "    data['longitude'] = data['longitude'].astype(float)\n",
    "    data['loadingOrder'] = data['loadingOrder'].astype(str)\n",
    "    data['latitude'] = data['latitude'].astype(float)\n",
    "    data['speed'] = data['speed'].astype(float)\n",
    "    data['direction'] = data['direction'].astype(float)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = get_data(train_data, mode='train')\n",
    "test_data = get_data(test_data, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['anchor_cnt', 'anchor_ratio', 'latitude_min', 'latitude_max', 'latitude_mean', 'latitude_median', 'longitude_min', 'longitude_max', 'longitude_mean', 'longitude_median', 'speed_min', 'speed_max', 'speed_mean', 'speed_median', 'direction_min', 'direction_max', 'direction_mean', 'direction_median']\n"
    }
   ],
   "source": [
    "# 代码参考：https://github.com/juzstu/TianChi_HaiYang\n",
    "def get_feature(df, mode='train'):\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    df.sort_values(['loadingOrder', 'timestamp'], inplace=True)\n",
    "    # 特征只选择经纬度、速度\\方向\n",
    "    df['lat_diff'] = df.groupby('loadingOrder')['latitude'].diff(1)\n",
    "    df['lon_diff'] = df.groupby('loadingOrder')['longitude'].diff(1)\n",
    "    df['speed_diff'] = df.groupby('loadingOrder')['speed'].diff(1)\n",
    "    df['diff_minutes'] = df.groupby('loadingOrder')['timestamp'].diff(1).dt.total_seconds() // 60\n",
    "    df['anchor'] = df.apply(lambda x: 1 if x['lat_diff'] <= 0.03 and x['lon_diff'] <= 0.03\n",
    "                            and x['speed_diff'] <= 0.3 and x['diff_minutes'] <= 10 else 0, axis=1)\n",
    "    \n",
    "    if mode=='train':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(mmax='max', count='count', mmin='min').reset_index()\n",
    "        # 读取数据的最大值-最小值，即确认时间间隔为label\n",
    "        group_df['label'] = (group_df['mmax'] - group_df['mmin']).dt.total_seconds()\n",
    "    elif mode=='test':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(count='count').reset_index()\n",
    "        \n",
    "    anchor_df = df.groupby('loadingOrder')['anchor'].agg('sum').reset_index()\n",
    "    anchor_df.columns = ['loadingOrder', 'anchor_cnt']\n",
    "    group_df = group_df.merge(anchor_df, on='loadingOrder', how='left')\n",
    "    group_df['anchor_ratio'] = group_df['anchor_cnt'] / group_df['count']\n",
    "\n",
    "    agg_function = ['min', 'max', 'mean', 'median']\n",
    "    agg_col = ['latitude', 'longitude', 'speed', 'direction']\n",
    "\n",
    "    group = df.groupby('loadingOrder')[agg_col].agg(agg_function).reset_index()\n",
    "    group.columns = ['loadingOrder'] + ['{}_{}'.format(i, j) for i in agg_col for j in agg_function]\n",
    "    group_df = group_df.merge(group, on='loadingOrder', how='left')\n",
    "\n",
    "    return group_df\n",
    "    \n",
    "train = get_feature(train_data, mode='train')\n",
    "test = get_feature(test_data, mode='test')\n",
    "features = [c for c in train.columns if c not in ['loadingOrder', 'label', 'mmin', 'mmax', 'count']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.10178e+10\tvalid_0's mse_score: 4.10178e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.70981e+11\tvalid_0's mse_score: 1.70981e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 5.57278e+10\tvalid_0's mse_score: 5.57278e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 2.00857e+11\tvalid_0's mse_score: 2.00857e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.50569e+10\tvalid_0's mse_score: 4.50569e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.60072e+11\tvalid_0's mse_score: 1.60072e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 5.43102e+10\tvalid_0's mse_score: 5.43102e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.67792e+11\tvalid_0's mse_score: 1.67792e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 3.82891e+10\tvalid_0's mse_score: 3.82891e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.646e+11\tvalid_0's mse_score: 1.646e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.48989e+10\tvalid_0's mse_score: 4.48989e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.67094e+11\tvalid_0's mse_score: 1.67094e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.83064e+10\tvalid_0's mse_score: 4.83064e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.88244e+11\tvalid_0's mse_score: 1.88244e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.1908e+10\tvalid_0's mse_score: 4.1908e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.78403e+11\tvalid_0's mse_score: 1.78403e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.75655e+10\tvalid_0's mse_score: 4.75655e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.51337e+11\tvalid_0's mse_score: 1.51337e+11\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 4.9642e+10\tvalid_0's mse_score: 4.9642e+10\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 1.85943e+11\tvalid_0's mse_score: 1.85943e+11\n"
    }
   ],
   "source": [
    "def mse_score_eval(preds, valid):\n",
    "    labels = valid.get_label()\n",
    "    scores = mean_squared_error(y_true=labels, y_pred=preds)\n",
    "    return 'mse_score', scores, True\n",
    "\n",
    "def build_model(train, test, pred, label, seed=1080, is_shuffle=True):\n",
    "    train_pred = np.zeros((train.shape[0], ))\n",
    "    test_pred = np.zeros((test.shape[0], ))\n",
    "    n_splits = 10\n",
    "    # Kfold\n",
    "    fold = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=seed)\n",
    "    kf_way = fold.split(train[pred])\n",
    "    # params\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 36,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 6,\n",
    "        'seed': 8,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction_seed': 7,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'nthread': 8,\n",
    "        'verbose': 1,\n",
    "    }\n",
    "    # train\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(kf_way, start=1):\n",
    "        train_x, train_y = train[pred].iloc[train_idx], train[label].iloc[train_idx]\n",
    "        valid_x, valid_y = train[pred].iloc[valid_idx], train[label].iloc[valid_idx]\n",
    "        # 数据加载\n",
    "        n_train = lgb.Dataset(train_x, label=train_y)\n",
    "        n_valid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=n_train,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[n_valid],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=mse_score_eval\n",
    "        )\n",
    "        train_pred[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration)\n",
    "        test_pred += clf.predict(test[pred], num_iteration=clf.best_iteration)/fold.n_splits\n",
    "    \n",
    "    test['label'] = test_pred\n",
    "    \n",
    "    return test[['loadingOrder', 'label']]\n",
    "\n",
    "result = build_model(train, test, features, 'label', is_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(result, on='loadingOrder', how='left')\n",
    "test_data['ETA'] = (test_data['onboardDate'] + test_data['label'].apply(lambda x:pd.Timedelta(seconds=x))).apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data.drop(['direction','TRANSPORT_TRACE'],axis=1,inplace=True)\n",
    "test_data['onboardDate'] = test_data['onboardDate'].apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data['creatDate'] = pd.datetime.now().strftime('%Y/%m/%d  %H:%M:%S')\n",
    "test_data['timestamp'] = test_data['temp_timestamp']\n",
    "# 整理columns顺序\n",
    "result = test_data[['loadingOrder', 'timestamp', 'longitude', 'latitude', 'carrierName', 'vesselMMSI', 'onboardDate', 'ETA', 'creatDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('result.csv', index=False)\n",
    "result.to_csv('result_tmp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         loadingOrder                 timestamp   longitude   latitude  \\\n0      CF946210847851  2019-04-02T02:42:28.000Z  138.471062  40.278787   \n1      CF946210847851  2019-04-02T02:59:28.000Z  138.552168  40.327785   \n2      CF946210847851  2019-04-02T03:07:28.000Z  138.588250  40.352542   \n3      CF946210847851  2019-04-02T03:43:28.000Z  138.751325  40.459447   \n4      CF946210847851  2019-04-02T04:29:28.000Z  138.969782  40.581485   \n...               ...                       ...         ...        ...   \n45451  XG479584941731  2019-01-13T03:56:08.000Z  104.633357   1.630708   \n45452  XG479584941731  2019-01-13T03:57:08.000Z  104.631958   1.626713   \n45453  XG479584941731  2019-01-13T03:57:38.000Z  104.631258   1.624615   \n45454  XG479584941731  2019-01-13T03:58:08.000Z  104.630597   1.622682   \n45455  XG479584941731  2019-01-13T03:59:08.000Z  104.629178   1.618552   \n\n      carrierName   vesselMMSI           onboardDate                   ETA  \\\n0          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/08  18:09:44   \n1          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/08  18:09:44   \n2          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/08  18:09:44   \n3          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/08  18:09:44   \n4          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/08  18:09:44   \n...           ...          ...                   ...                   ...   \n45451      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/16  16:44:57   \n45452      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/16  16:44:57   \n45453      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/16  16:44:57   \n45454      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/16  16:44:57   \n45455      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/16  16:44:57   \n\n                  creatDate  \n0      2020/06/14  19:34:51  \n1      2020/06/14  19:34:51  \n2      2020/06/14  19:34:51  \n3      2020/06/14  19:34:51  \n4      2020/06/14  19:34:51  \n...                     ...  \n45451  2020/06/14  19:34:51  \n45452  2020/06/14  19:34:51  \n45453  2020/06/14  19:34:51  \n45454  2020/06/14  19:34:51  \n45455  2020/06/14  19:34:51  \n\n[45456 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loadingOrder</th>\n      <th>timestamp</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>carrierName</th>\n      <th>vesselMMSI</th>\n      <th>onboardDate</th>\n      <th>ETA</th>\n      <th>creatDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T02:42:28.000Z</td>\n      <td>138.471062</td>\n      <td>40.278787</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/04/08  18:09:44</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T02:59:28.000Z</td>\n      <td>138.552168</td>\n      <td>40.327785</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/04/08  18:09:44</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T03:07:28.000Z</td>\n      <td>138.588250</td>\n      <td>40.352542</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/04/08  18:09:44</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T03:43:28.000Z</td>\n      <td>138.751325</td>\n      <td>40.459447</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/04/08  18:09:44</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T04:29:28.000Z</td>\n      <td>138.969782</td>\n      <td>40.581485</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/04/08  18:09:44</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45451</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:56:08.000Z</td>\n      <td>104.633357</td>\n      <td>1.630708</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/16  16:44:57</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>45452</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:57:08.000Z</td>\n      <td>104.631958</td>\n      <td>1.626713</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/16  16:44:57</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>45453</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:57:38.000Z</td>\n      <td>104.631258</td>\n      <td>1.624615</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/16  16:44:57</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>45454</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:58:08.000Z</td>\n      <td>104.630597</td>\n      <td>1.622682</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/16  16:44:57</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n    <tr>\n      <th>45455</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:59:08.000Z</td>\n      <td>104.629178</td>\n      <td>1.618552</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/16  16:44:57</td>\n      <td>2020/06/14  19:34:51</td>\n    </tr>\n  </tbody>\n</table>\n<p>45456 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}