{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:40169</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>16.63 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:40169' processes=8 threads=16, memory=16.63 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "#from dask_ml.metrics import mean_squared_error\n",
    "#from dask_ml.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个数据预处理函数\n",
    "def get_data(data, mode='train'): # 针对训练数据 和 测试数据 分别将部分关于时间的列转换为 datetime 时间格式\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    if mode=='train':\n",
    "        data['vesselNextportETA'] = pd.to_datetime(data['vesselNextportETA'], infer_datetime_format=True) # 使用自动识别推理出的时间格式，把这'vesselNextportETA'转化为时间格式\n",
    "    elif mode=='test':\n",
    "        data['temp_timestamp'] = data['timestamp'] # 拷贝'timestamp'列\n",
    "        data['onboardDate'] = pd.to_datetime(data['onboardDate'], infer_datetime_format=True)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], infer_datetime_format=True)\n",
    "    data['longitude'] = data['longitude'].astype(float)\n",
    "    data['loadingOrder'] = data['loadingOrder'].astype(str)\n",
    "    data['latitude'] = data['latitude'].astype(float)\n",
    "    data['speed'] = data['speed'].astype(float)\n",
    "    data['direction'] = data['direction'].astype(float) # 把特征都变成浮点数类型\n",
    "    \n",
    "    #data = data.compute()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做特征工程的函数\n",
    "def get_feature(df, mode='train'):\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    df.sort_values(['loadingOrder', 'timestamp'], inplace=True) # 将数据按 订单号 和 时间戳 两列进行 升序排列，排列结果替换元数据\n",
    "    # 特征只选择经纬度、速度\\方向\n",
    "    df['lat_diff'] = df.groupby('loadingOrder')['latitude'].diff(1) # 返回按 订单号 分类以后 维度的差分(变化)\n",
    "    df['lon_diff'] = df.groupby('loadingOrder')['longitude'].diff(1) # 返回按 订单号 分类以后 经度的差分(变化)\n",
    "    df['speed_diff'] = df.groupby('loadingOrder')['speed'].diff(1) # 返回按 订单号 分类以后 速度的差分(变化)\n",
    "    df['diff_minutes'] = df.groupby('loadingOrder')['timestamp'].diff(1).dt.total_seconds() // 60 # 返回按 订单号 分类以后 时间的差分，差分化成秒，除以60转化为时间\n",
    "    \n",
    "    df = dd.from_pandas(df, npartitions=12)\n",
    "    df['anchor'] = df.apply(lambda x: 1 if x['lat_diff'] <= 0.03 and x['lon_diff'] <= 0.03\n",
    "                            and x['speed_diff'] <= 0.3 and x['diff_minutes'] <= 10 else 0, axis=1) # 对每一列应用函数，判断船是否抛锚停下。\n",
    "    df = df.compute()\n",
    "    \n",
    "    if mode=='train':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(mmax='max', count='count', mmin='min').reset_index() #对订单号进行分组，然后对一组内时间戳合计，统计一个订单号时间戳下所有行，\n",
    "        # 每个属性的最大值、计数、最小值，并且重新设置索引index，将原来的index加入到df中成为一列\n",
    "        # 读取数据的最大值-最小值，即确认时间间隔为label            # 即将时间间隔作为一个特征\n",
    "        group_df['label'] = (group_df['mmax'] - group_df['mmin']).dt.total_seconds()\n",
    "    elif mode=='test':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(count='count').reset_index()\n",
    "        \n",
    "    anchor_df = df.groupby('loadingOrder')['anchor'].agg('sum').reset_index()\n",
    "    anchor_df.columns = ['loadingOrder', 'anchor_cnt']\n",
    "    group_df = group_df.merge(anchor_df, on='loadingOrder', how='left')\n",
    "    group_df['anchor_ratio'] = group_df['anchor_cnt'] / group_df['count']\n",
    "\n",
    "    agg_function = ['min', 'max', 'mean', 'median']\n",
    "    agg_col = ['latitude', 'longitude', 'speed', 'direction']\n",
    "\n",
    "    group = df.groupby('loadingOrder')[agg_col].agg(agg_function).reset_index()\n",
    "    group.columns = ['loadingOrder'] + ['{}_{}'.format(i, j) for i in agg_col for j in agg_function]\n",
    "    group_df = group_df.merge(group, on='loadingOrder', how='left')\n",
    "    \n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_score_eval(preds, valid):\n",
    "    labels = valid.get_label()\n",
    "    scores = mean_squared_error(y_true=labels, y_pred=preds)\n",
    "    return 'mse_score', scores, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline只用到gps定位数据，即train_gps_path\n",
    "train_gps_path = '/run/media/liweikang/OS/Users/Li Weikang/Desktop/train0523.csv'\n",
    "test_data_path = '/run/media/liweikang/OS/Users/Li Weikang/Desktop/A_testData0531.csv'\n",
    "order_data_path = '/run/media/liweikang/OS/Users/Li Weikang/Desktop/loadingOrderEvent.csv'\n",
    "port_data_path = '/run/media/liweikang/OS/Users/Li Weikang/Desktop/port.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDATA = 5000000 # 一次读NDATA行\n",
    "Thresold = 10000000 # 总共要读多少行\n",
    "weight = float(NDATA)/Thresold\n",
    "\n",
    "def set_data_columns(data):\n",
    "    # 按照官网上对运单GPS数据的说明，重命名训练数据的列名\n",
    "    data.columns = ['loadingOrder','carrierName','timestamp','longitude',\n",
    "                  'latitude','vesselMMSI','speed','direction','vesselNextport',\n",
    "                  'vesselNextportETA','vesselStatus','vesselDatasource','TRANSPORT_TRACE']\n",
    "    return data\n",
    "\n",
    "# params\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 36,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 6,\n",
    "    'seed': 8,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction_seed': 7,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'nthread': 8,\n",
    "    'verbose': 1,\n",
    "}\n",
    "sum = 0\n",
    "clf = None\n",
    "label = 'label'\n",
    "seed=1080 \n",
    "is_shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data = get_data(test_data, mode='test') # 预处理测试数据\n",
    "test = get_feature(test_data, mode='test')\n",
    "test_pred = da.zeros((test.shape[0], )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.33182e+11\tvalid_0's mse_score: 1.33182e+11\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l2: 4.82078e+11\tvalid_0's mse_score: 4.82078e+11\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l2: 4.89644e+10\tvalid_0's mse_score: 4.89644e+10\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l2: 1.20675e+11\tvalid_0's mse_score: 1.20675e+11\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 2.96339e+10\tvalid_0's mse_score: 2.96339e+10\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l2: 4.20532e+10\tvalid_0's mse_score: 4.20532e+10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's l2: 1.84784e+10\tvalid_0's mse_score: 1.84784e+10\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's l2: 1.99161e+10\tvalid_0's mse_score: 1.99161e+10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 9.61045e+09\tvalid_0's mse_score: 9.61045e+09\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's l2: 1.01792e+10\tvalid_0's mse_score: 1.01792e+10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\tvalid_0's l2: 1.71755e+10\tvalid_0's mse_score: 1.71755e+10\n",
      "Early stopping, best iteration is:\n",
      "[506]\tvalid_0's l2: 6.76662e+10\tvalid_0's mse_score: 6.76662e+10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\tvalid_0's l2: 1.09757e+10\tvalid_0's mse_score: 1.09757e+10\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's l2: 2.48652e+10\tvalid_0's mse_score: 2.48652e+10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\tvalid_0's l2: 5.76118e+09\tvalid_0's mse_score: 5.76118e+09\n",
      "Early stopping, best iteration is:\n",
      "[708]\tvalid_0's l2: 8.6153e+09\tvalid_0's mse_score: 8.6153e+09\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\tvalid_0's l2: 3.62802e+09\tvalid_0's mse_score: 3.62802e+09\n",
      "Early stopping, best iteration is:\n",
      "[809]\tvalid_0's l2: 4.15275e+09\tvalid_0's mse_score: 4.15275e+09\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's l2: 3.87252e+09\tvalid_0's mse_score: 3.87252e+09\n",
      "Early stopping, best iteration is:\n",
      "[910]\tvalid_0's l2: 4.22823e+09\tvalid_0's mse_score: 4.22823e+09\n"
     ]
    }
   ],
   "source": [
    "for batch_data in pd.read_csv(train_gps_path, chunksize = NDATA):\n",
    "    sum += NDATA\n",
    "    batch_data = set_data_columns(batch_data)\n",
    "    batch_data = get_data(batch_data, mode = 'train')\n",
    "    batch_train = get_feature(batch_data, mode='train')\n",
    "    features = [c for c in batch_train.columns if c not in ['loadingOrder', 'label', 'mmin', 'mmax', 'count']]\n",
    "    pred = features\n",
    "\n",
    "    train_pred = da.zeros((batch_train.shape[0], ))\n",
    "    n_splits = 5\n",
    "    # Kfold\n",
    "    fold = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=seed)\n",
    "    kf_way = fold.split(batch_train[pred])\n",
    "    \n",
    "    # train\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(kf_way, start=1):\n",
    "        train_x, train_y = batch_train[pred].iloc[train_idx], batch_train[label].iloc[train_idx]\n",
    "        valid_x, valid_y = batch_train[pred].iloc[valid_idx], batch_train[label].iloc[valid_idx]\n",
    "        # 数据加载\n",
    "        n_train = lgb.Dataset(train_x, label=train_y)\n",
    "        n_valid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=n_train,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[n_valid],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=mse_score_eval,\n",
    "            init_model=clf,\n",
    "            keep_training_booster = True,\n",
    "        )\n",
    "        test_pred += clf.predict(test[pred], num_iteration=clf.best_iteration)*weight/fold.n_splits\n",
    "    if sum >= Thresold:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test_pred\n",
    "result = test[['loadingOrder', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(result, on='loadingOrder', how='left')\n",
    "test_data['ETA'] = (test_data['onboardDate'] + test_data['label'].apply(lambda x:pd.Timedelta(seconds=x))).apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data.drop(['direction','TRANSPORT_TRACE'],axis=1,inplace=True)\n",
    "test_data['onboardDate'] = test_data['onboardDate'].apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data['creatDate'] = pd.datetime.now().strftime('%Y/%m/%d  %H:%M:%S')\n",
    "test_data['timestamp'] = test_data['temp_timestamp']\n",
    "# 整理columns顺序\n",
    "result = test_data[['loadingOrder', 'timestamp', 'longitude', 'latitude', 'carrierName', 'vesselMMSI', 'onboardDate', 'ETA', 'creatDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loadingOrder</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>carrierName</th>\n",
       "      <th>vesselMMSI</th>\n",
       "      <th>onboardDate</th>\n",
       "      <th>ETA</th>\n",
       "      <th>creatDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T02:42:28.000Z</td>\n",
       "      <td>138.471062</td>\n",
       "      <td>40.278787</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/06  06:21:29</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T02:59:28.000Z</td>\n",
       "      <td>138.552168</td>\n",
       "      <td>40.327785</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/06  06:21:29</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T03:07:28.000Z</td>\n",
       "      <td>138.588250</td>\n",
       "      <td>40.352542</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/06  06:21:29</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T03:43:28.000Z</td>\n",
       "      <td>138.751325</td>\n",
       "      <td>40.459447</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/06  06:21:29</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T04:29:28.000Z</td>\n",
       "      <td>138.969782</td>\n",
       "      <td>40.581485</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/06  06:21:29</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45451</th>\n",
       "      <td>XG479584941731</td>\n",
       "      <td>2019-01-13T03:56:08.000Z</td>\n",
       "      <td>104.633357</td>\n",
       "      <td>1.630708</td>\n",
       "      <td>JCMFTA</td>\n",
       "      <td>U2218600548</td>\n",
       "      <td>2019/01/10  00:27:58</td>\n",
       "      <td>2019/01/14  15:18:04</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45452</th>\n",
       "      <td>XG479584941731</td>\n",
       "      <td>2019-01-13T03:57:08.000Z</td>\n",
       "      <td>104.631958</td>\n",
       "      <td>1.626713</td>\n",
       "      <td>JCMFTA</td>\n",
       "      <td>U2218600548</td>\n",
       "      <td>2019/01/10  00:27:58</td>\n",
       "      <td>2019/01/14  15:18:04</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45453</th>\n",
       "      <td>XG479584941731</td>\n",
       "      <td>2019-01-13T03:57:38.000Z</td>\n",
       "      <td>104.631258</td>\n",
       "      <td>1.624615</td>\n",
       "      <td>JCMFTA</td>\n",
       "      <td>U2218600548</td>\n",
       "      <td>2019/01/10  00:27:58</td>\n",
       "      <td>2019/01/14  15:18:04</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45454</th>\n",
       "      <td>XG479584941731</td>\n",
       "      <td>2019-01-13T03:58:08.000Z</td>\n",
       "      <td>104.630597</td>\n",
       "      <td>1.622682</td>\n",
       "      <td>JCMFTA</td>\n",
       "      <td>U2218600548</td>\n",
       "      <td>2019/01/10  00:27:58</td>\n",
       "      <td>2019/01/14  15:18:04</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45455</th>\n",
       "      <td>XG479584941731</td>\n",
       "      <td>2019-01-13T03:59:08.000Z</td>\n",
       "      <td>104.629178</td>\n",
       "      <td>1.618552</td>\n",
       "      <td>JCMFTA</td>\n",
       "      <td>U2218600548</td>\n",
       "      <td>2019/01/10  00:27:58</td>\n",
       "      <td>2019/01/14  15:18:04</td>\n",
       "      <td>2020/06/08  21:38:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45456 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loadingOrder                 timestamp   longitude   latitude  \\\n",
       "0      CF946210847851  2019-04-02T02:42:28.000Z  138.471062  40.278787   \n",
       "1      CF946210847851  2019-04-02T02:59:28.000Z  138.552168  40.327785   \n",
       "2      CF946210847851  2019-04-02T03:07:28.000Z  138.588250  40.352542   \n",
       "3      CF946210847851  2019-04-02T03:43:28.000Z  138.751325  40.459447   \n",
       "4      CF946210847851  2019-04-02T04:29:28.000Z  138.969782  40.581485   \n",
       "...               ...                       ...         ...        ...   \n",
       "45451  XG479584941731  2019-01-13T03:56:08.000Z  104.633357   1.630708   \n",
       "45452  XG479584941731  2019-01-13T03:57:08.000Z  104.631958   1.626713   \n",
       "45453  XG479584941731  2019-01-13T03:57:38.000Z  104.631258   1.624615   \n",
       "45454  XG479584941731  2019-01-13T03:58:08.000Z  104.630597   1.622682   \n",
       "45455  XG479584941731  2019-01-13T03:59:08.000Z  104.629178   1.618552   \n",
       "\n",
       "      carrierName   vesselMMSI           onboardDate                   ETA  \\\n",
       "0          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/06  06:21:29   \n",
       "1          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/06  06:21:29   \n",
       "2          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/06  06:21:29   \n",
       "3          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/06  06:21:29   \n",
       "4          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/06  06:21:29   \n",
       "...           ...          ...                   ...                   ...   \n",
       "45451      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/14  15:18:04   \n",
       "45452      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/14  15:18:04   \n",
       "45453      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/14  15:18:04   \n",
       "45454      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/14  15:18:04   \n",
       "45455      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/14  15:18:04   \n",
       "\n",
       "                  creatDate  \n",
       "0      2020/06/08  21:38:53  \n",
       "1      2020/06/08  21:38:53  \n",
       "2      2020/06/08  21:38:53  \n",
       "3      2020/06/08  21:38:53  \n",
       "4      2020/06/08  21:38:53  \n",
       "...                     ...  \n",
       "45451  2020/06/08  21:38:53  \n",
       "45452  2020/06/08  21:38:53  \n",
       "45453  2020/06/08  21:38:53  \n",
       "45454  2020/06/08  21:38:53  \n",
       "45455  2020/06/08  21:38:53  \n",
       "\n",
       "[45456 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
